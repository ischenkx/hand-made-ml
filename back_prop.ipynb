{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb61614",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4aeec9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall ray\n",
    "# !pip install -U \"<PREFIX PATH>\\ray-2.0.0.dev0-cp38-cp38-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "id": "7b8a281b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc36163",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import ray\n",
    "np.seterr(all=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345f8640",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "RayContext(dashboard_url='', python_version='3.8.8', ray_version='2.0.0.dev0', ray_commit='a34dcfce85deaaa4590b7edd68649af16ac8b571', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:62214', 'raylet_socket_name': 'tcp://127.0.0.1:65174', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\Roman\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-04-23_14-05-35_860726_60840', 'metrics_export_port': 63505, 'gcs_address': '127.0.0.1:63884', 'address': '127.0.0.1:63884', 'node_id': '194daac6e14c1e3f4c94f796ae015e1316eb5670290016685585428c'})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c038e8b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7298062",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_d(x):\n",
    "    return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_d(z):\n",
    "    return np.greater(z, 0).astype(int)\n",
    "\n",
    "# softmax\n",
    "def softmax(x):\n",
    "    exp_element=np.exp(x-x.max())\n",
    "    return exp_element/np.sum(exp_element,axis=0)\n",
    "\n",
    "# derivative of softmax\n",
    "def softmax_d(x):\n",
    "    exp_element=np.exp(x-x.max())\n",
    "    return exp_element/np.sum(exp_element,axis=0)*(1-exp_element/np.sum(exp_element,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2ea220",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_activator = (sigmoid, sigmoid_d)\n",
    "relu_activator = (relu, relu_d)\n",
    "softmax_activator = (softmax, softmax_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf32b63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mse_loss(outputs, target):\n",
    "    return ((outputs - target) ** 2).sum() / len(outputs)\n",
    "\n",
    "def mse_loss_d(outputs, target):\n",
    "    return 2 * (outputs - target) / len(outputs)\n",
    "\n",
    "def cross_entropy(model_output, target):\n",
    "    if model_output.shape != target.shape:\n",
    "        raise ValueError('Dimensions of model output and target do not match')\n",
    "    eps = np.finfo(model_output.dtype).eps\n",
    "    model_output = np.clip(model_output, eps, 1- eps)\n",
    "    return -np.sum(target * np.log(model_output))/model_output.shape[0]\n",
    "\n",
    "def cross_entropy_d(model_output, target):\n",
    "    return model_output - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdc0f33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse_loss_set = (mse_loss, mse_loss_d)\n",
    "crossentropy_loss_set = (cross_entropy, cross_entropy_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d769ea20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def layer(neurons, fset, bias=True):\n",
    "    act = fset[0] if fset is not None else None\n",
    "    actd = fset[1] if fset is not None else None\n",
    "    \n",
    "    return {\n",
    "        'activation': act,\n",
    "        'activation_d': actd,\n",
    "        'neurons': neurons,\n",
    "        'bias': bias\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class RMSPropOptimizer(object):\n",
    "    def __init__(self, model, alpha, momentum, forget_factor):\n",
    "        self.alpha = alpha\n",
    "        self.momentum = momentum\n",
    "        self.forget_factor = forget_factor\n",
    "        self.model = model\n",
    "        self.deltas = [np.zeros(wmat) for wmat in self.model.weights_layout()]\n",
    "        self.rms_prop_deltas = [np.zeros(wmat) for wmat in self.model.weights_layout()]\n",
    "\n",
    "    def step(self, grad):\n",
    "        eps = 1e-8\n",
    "        for i, wg in enumerate(grad):\n",
    "            # RMSProp\n",
    "            v = self.forget_factor * self.rms_prop_deltas[i] + \\\n",
    "                (1 - self.forget_factor) * (wg ** 2)\n",
    "\n",
    "            # delta for momentum\n",
    "            delta = self.alpha * wg / (v ** 0.5 + eps) + \\\n",
    "                    self.momentum * self.deltas[i]\n",
    "\n",
    "            self.model.weights[i] -= delta\n",
    "            self.deltas[i] = delta\n",
    "            self.rms_prop_deltas[i] = v\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((4,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "class RayGradientCalculator(object):\n",
    "    @ray.remote\n",
    "    class Actor(object):\n",
    "        # initializer is a dict of arguments to a model copy\n",
    "        def __init__(self, initializer):\n",
    "            initializer['initialize'] = False\n",
    "            self.model = Model(**initializer)\n",
    "            self.model.reset_inputs()\n",
    "            self.model.reset_outputs()\n",
    "\n",
    "        def calc_weight_grad(self, inp, tar, weights):\n",
    "            self.model.weights = weights\n",
    "            self.model.forward(inp)\n",
    "            grad = self.model.calc_input_grad(tar)\n",
    "            return self.model.calc_weight_grad(grad)\n",
    "\n",
    "    def __init__(self, model, workers):\n",
    "        self.max_workers = workers\n",
    "        self.model = model\n",
    "        self.initializer = None\n",
    "        self.pool = None\n",
    "        self._initialize()\n",
    "\n",
    "\n",
    "    def _initialize(self):\n",
    "        self.initializer = {\n",
    "            'layers': self.model.layers,\n",
    "            'loss_set': (self.model.loss, self.model.loss_d),\n",
    "            'dtype': self.model.dtype,\n",
    "            'initialize': False\n",
    "        }\n",
    "\n",
    "        self.pool = []\n",
    "        for _ in range(self.max_workers):\n",
    "            self.pool.append(RayGradientCalculator.Actor.remote(self.initializer))\n",
    "\n",
    "    def _get_actor(self):\n",
    "        if len(self.pool) == 0:\n",
    "            return None\n",
    "        return self.pool.pop()\n",
    "\n",
    "    def _release_actors(self, *actors):\n",
    "        for actor in actors:\n",
    "            if actor not in self.pool:\n",
    "                self.pool.append(actor)\n",
    "\n",
    "    def run(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        if batch_size == 0:\n",
    "            return\n",
    "\n",
    "        object_refs = []\n",
    "\n",
    "        weights_ref = ray.put(self.model.weights)\n",
    "        object_refs.append(weights_ref)\n",
    "\n",
    "        result_w_grad = None\n",
    "\n",
    "        idx = 0\n",
    "\n",
    "        while idx < len(batch):\n",
    "            gradient_tasks = []\n",
    "            actors = []\n",
    "\n",
    "            while idx < len(batch):\n",
    "                trainer = self._get_actor()\n",
    "                if trainer is None:\n",
    "                    break\n",
    "\n",
    "                inp, tar = batch[idx]\n",
    "                idx += 1\n",
    "\n",
    "                inp_ref = ray.put(inp)\n",
    "                tar_ref = ray.put(tar)\n",
    "\n",
    "                object_refs.append(inp_ref)\n",
    "                object_refs.append(tar_ref)\n",
    "                actors.append(trainer)\n",
    "\n",
    "                task = trainer.calc_weight_grad.remote(inp_ref, tar_ref, weights_ref)\n",
    "                gradient_tasks.append(task)\n",
    "\n",
    "            grads = ray.get(gradient_tasks)\n",
    "\n",
    "            w_grad = list(map(lambda x: sum(x) / batch_size, zip(*grads)))\n",
    "\n",
    "            if result_w_grad is None:\n",
    "                result_w_grad = w_grad\n",
    "            else:\n",
    "                for i in range(len(w_grad)):\n",
    "                    result_w_grad[i] += w_grad[i]\n",
    "\n",
    "            del gradient_tasks\n",
    "            self._release_actors(*actors)\n",
    "\n",
    "        del object_refs\n",
    "\n",
    "        return result_w_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edb9d88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.34])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 loss_set,\n",
    "                 initialize=True,\n",
    "                 dtype=np.float64,\n",
    "                 ):\n",
    "        self.layers = layers\n",
    "        self.dtype = dtype\n",
    "        self.loss = loss_set[0]\n",
    "        self.loss_d = loss_set[1]\n",
    "        # self.trainers = []\n",
    "\n",
    "        self.weights = None\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "\n",
    "        if initialize:\n",
    "            self.initialize()\n",
    "\n",
    "    def zero_array(self, shape):\n",
    "        return np.zeros(shape, dtype=self.dtype)\n",
    "\n",
    "    def random_array(self, shape):\n",
    "        return np.random.random(shape).astype(self.dtype)\n",
    "\n",
    "    def layer(self, layer):\n",
    "        return self.layers[layer]\n",
    "    \n",
    "    def has_bias(self, layer):\n",
    "        # output layer can't have a bias\n",
    "        if layer == self.count_layers() - 1:\n",
    "            return False\n",
    "        return self.layer(layer)['bias']\n",
    "    \n",
    "    # returns an activation function for the layer\n",
    "    def activator(self, layer):\n",
    "        return self.layer(layer)['activation']\n",
    "    \n",
    "    # returns a derivative of an activation function for the layer\n",
    "    def activator_d(self, layer):\n",
    "        return self.layer(layer)['activation_d']\n",
    "    \n",
    "    # returns the amount of neurons in the layer\n",
    "    def count_neurons(self, layer):\n",
    "        bias = int(self.has_bias(layer))\n",
    "        return self.layer(layer)['neurons'] + bias\n",
    "    \n",
    "    # returns the amount of layers in the model\n",
    "    def count_layers(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "    def reset_outputs(self):\n",
    "        self.outputs = []\n",
    "        for i in range(self.count_layers()):\n",
    "            neurons = self.count_neurons(i)\n",
    "            self.outputs.append(self.zero_array((neurons,)))\n",
    "    \n",
    "    def reset_inputs(self):\n",
    "        self.inputs = []\n",
    "        for i in range(self.count_layers()):\n",
    "            neurons = self.count_neurons(i)\n",
    "            self.inputs.append(self.zero_array((neurons,)))\n",
    "    \n",
    "    def reset_weights(self):\n",
    "        self.weights = []\n",
    "        for i in range(self.count_layers()):\n",
    "            neurons = self.count_neurons(i)\n",
    "            if i > 0:\n",
    "                w_shape = (self.count_neurons(i - 1), neurons)\n",
    "                self.weights.append(self.random_array(w_shape))\n",
    "            \n",
    "    def initialize(self):\n",
    "        self.reset_inputs()\n",
    "        self.reset_outputs()\n",
    "        self.reset_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(self.inputs[0]) - int(self.has_bias(0)) != len(x):\n",
    "            raise Exception('incorrect input size')\n",
    "\n",
    "        for i, val in enumerate(x):\n",
    "            self.inputs[0][i] = val\n",
    "            self.outputs[0][i] = val\n",
    "\n",
    "        if self.has_bias(0):\n",
    "            self.inputs[0][-1] = 1\n",
    "            self.outputs[0][-1] = 1\n",
    "\n",
    "        for i in range(1, self.count_layers()):\n",
    "            activate = self.activator(i)\n",
    "            self.inputs[i] = self.outputs[i-1] @ self.weights[i-1]\n",
    "            if activate is not None:\n",
    "                self.outputs[i] = activate(self.inputs[i])\n",
    "            else:\n",
    "                self.outputs[i] = self.inputs[i].copy()\n",
    "\n",
    "            if self.has_bias(i):\n",
    "                self.outputs[i][-1] = 1\n",
    "                self.inputs[i][-1] = 1\n",
    "\n",
    "        return self.outputs[-1].copy()\n",
    "    \n",
    "    def calc_input_grad(self, target):\n",
    "        grad = [\n",
    "            self.zero_array((self.count_neurons(i),))\n",
    "                for i in range(self.count_layers())\n",
    "        ]\n",
    "\n",
    "        output_layer = self.count_layers() - 1\n",
    "        o_activate_d = self.activator_d(output_layer)\n",
    "        o_outputs = self.outputs[output_layer]\n",
    "        o_inputs = self.inputs[output_layer]\n",
    "        grad[output_layer] = self.loss_d(o_outputs, target)\n",
    "        \n",
    "        if o_activate_d is not None:\n",
    "            grad[output_layer] *= o_activate_d(o_inputs)            \n",
    "        for i in range(self.count_layers() - 2, 0, -1):\n",
    "            activate_d = self.activator_d(i)\n",
    "            grad[i] = grad[i + 1] @ self.weights[i].T\n",
    "            if activate_d is not None:\n",
    "                grad[i] *= activate_d(self.inputs[i])\n",
    "        return grad\n",
    "    \n",
    "    def weights_layout(self):\n",
    "        return [wmat.shape for wmat in self.weights]\n",
    "\n",
    "    def calc_weight_grad(self, input_grad):\n",
    "        layers = self.count_layers()\n",
    "        w_grad = [None] * (layers - 1)\n",
    "        for output_layer in range(layers-1):\n",
    "            inputs = self.outputs[output_layer]\n",
    "            grad = input_grad[output_layer + 1]\n",
    "            w_grad[output_layer] = np.outer(inputs, grad)\n",
    "        return w_grad\n",
    "\n",
    "test_model = Model(\n",
    "    (\n",
    "        layer(3, None, False),\n",
    "        layer(2, None, False),\n",
    "        layer(1, None, False)\n",
    "    ),\n",
    "    mse_loss_set\n",
    ")\n",
    "\n",
    "test_model.weights = [\n",
    "    np.array([\n",
    "        [0.1, 0.2],\n",
    "        [0.3, 0.4],\n",
    "        [0.5, 0.6]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0.3],\n",
    "        [0.6]\n",
    "    ])\n",
    "]\n",
    "\n",
    "# test_model.log_pool_info()\n",
    "\n",
    "# expected result is 2.34\n",
    "test_model.forward([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8cdc375",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [0.73714542]\n",
      "[0 1] [0.759092]\n",
      "[1 0] [0.80487922]\n",
      "[1 1] [0.82386688]\n",
      "\n",
      "epoch: 0\n",
      "[0 0] [0.73714542]\n",
      "[0 1] [0.759092]\n",
      "[1 0] [0.80487922]\n",
      "[1 1] [0.82386688]\n",
      "--------------------\n",
      "epoch: 400\n",
      "[0 0] [-0.0993933]\n",
      "[0 1] [0.66363996]\n",
      "[1 0] [0.66363091]\n",
      "[1 1] [0.3613894]\n",
      "--------------------\n",
      "epoch: 800\n",
      "[0 0] [-0.12663424]\n",
      "[0 1] [0.71768317]\n",
      "[1 0] [0.71768227]\n",
      "[1 1] [0.27750187]\n",
      "--------------------\n",
      "epoch: 1200\n",
      "[0 0] [-0.14083222]\n",
      "[0 1] [0.75160192]\n",
      "[1 0] [0.75160182]\n",
      "[1 1] [0.1990651]\n",
      "--------------------\n",
      "epoch: 1600\n",
      "[0 0] [-0.14968919]\n",
      "[0 1] [0.77705273]\n",
      "[1 0] [0.77705272]\n",
      "[1 1] [0.13386574]\n",
      "--------------------\n",
      "epoch: 2000\n",
      "[0 0] [-0.15553041]\n",
      "[0 1] [0.79656388]\n",
      "[1 0] [0.79656388]\n",
      "[1 1] [0.08188127]\n",
      "--------------------\n",
      "epoch: 2400\n",
      "[0 0] [-0.15949746]\n",
      "[0 1] [0.81149917]\n",
      "[1 0] [0.81149917]\n",
      "[1 1] [0.04135619]\n",
      "--------------------\n",
      "epoch: 2800\n",
      "[0 0] [-0.16224065]\n",
      "[0 1] [0.82286603]\n",
      "[1 0] [0.82286603]\n",
      "[1 1] [0.01026989]\n",
      "--------------------\n",
      "epoch: 3200\n",
      "[0 0] [-0.16415667]\n",
      "[0 1] [0.83146467]\n",
      "[1 0] [0.83146467]\n",
      "[1 1] [-0.01325614]\n",
      "--------------------\n",
      "epoch: 3600\n",
      "[0 0] [-0.16549992]\n",
      "[0 1] [0.83793595]\n",
      "[1 0] [0.83793595]\n",
      "[1 1] [-0.03084288]\n",
      "--------------------\n",
      "[0 0] [-0.16644018]\n",
      "[0 1] [0.84278835]\n",
      "[1 0] [0.84278835]\n",
      "[1 1] [-0.04383403]\n"
     ]
    }
   ],
   "source": [
    "layout = (\n",
    "    layer(2, None),\n",
    "    layer(2, sigmoid_activator),\n",
    "    layer(1, None)\n",
    ")\n",
    "\n",
    "xor_model = Model(layout, mse_loss_set)\n",
    "\n",
    "grad_calc = RayGradientCalculator(xor_model, 4)\n",
    "optimizer = RMSPropOptimizer(xor_model, 0.1, 0.01, 0.01)\n",
    "\n",
    "dataset = [\n",
    "    (np.array([0, 0]), np.array([0])),\n",
    "    (np.array([0, 1]), np.array([1])),\n",
    "    (np.array([1, 0]), np.array([1])),\n",
    "    (np.array([1, 1]), np.array([0])),\n",
    "]\n",
    "\n",
    "for inp, tar in dataset:\n",
    "    print(inp, xor_model.forward(inp))\n",
    "print()\n",
    "\n",
    "for epoch in range(4000):\n",
    "#     print(epoch)\n",
    "    if epoch % 400 == 0:\n",
    "        print('epoch:', epoch)\n",
    "        for inp, tar in dataset:\n",
    "            print(inp, xor_model.forward(inp))\n",
    "        # xor_model.log_pool_info()\n",
    "        print('--------------------')\n",
    "    grad = grad_calc.run(dataset)\n",
    "    optimizer.step(grad)\n",
    "\n",
    "for inp, tar in dataset:\n",
    "    print(inp, xor_model.forward(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cecce114",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "torch_ds = torchvision.datasets.MNIST('/files/', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d77db2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28 at 0x1BA5F85DE20>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9klEQVR4nGNgGIbAsPb1/39VDAwMDAy8bVssUeQW//r79+/fP/YMDAwCx//+LUWSMlnx5+9VBR7DXGYGBoa5f/9uZ0OSXP03XZgHyo7+/vc1B7KhP/4KQ1mie7/+/eyLYuPJvxmcDAwMDO5VT/7+/VuI6lSh439vX79+/frXv3///t3Gj+YRkaVn//79u3/9wb9/7wpg+lPE2NiYm8H67988rMHAwMDAEPv3ljAuuYC3f/Nxajzy97oYgseEIsfL9a37FW4bD+E01Pg1qo0oxsoI/TyNU+fsv5tQ+Cg63zBMYsGp0//v32ZkPorKG4t+zsWpEx0AADUnXUEwaybFAAAAAElFTkSuQmCC\n"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_ds[54][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be75bc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for i in range(len(torch_ds)):\n",
    "    img, tar = torch_ds[i]\n",
    "    inp = transform(img).numpy().flatten()\n",
    "    target = [0] * 10\n",
    "    target[tar] = 1\n",
    "    train_dataset.append((inp, target, img))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b302750",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layout = (\n",
    "    layer(784, None),\n",
    "    layer(64, sigmoid_activator),\n",
    "    layer(10, sigmoid_activator),\n",
    ")\n",
    "\n",
    "model = Model(layout, mse_loss_set)\n",
    "\n",
    "gradient_calculator = RayGradientCalculator(model, 64)\n",
    "rms_prop_optimizer = RMSPropOptimizer(model, 0.01, 0.01, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7cc12e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "batches = []\n",
    "\n",
    "next_batch = []\n",
    "\n",
    "for inp, tar, img in train_dataset:\n",
    "    next_batch.append((inp, tar))\n",
    "    if len(next_batch) == BATCH_SIZE:\n",
    "        batches.append(next_batch)\n",
    "        next_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f606ffe8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, train_dataset, count=512):\n",
    "    guessed = 0\n",
    "    for _ in range(count):\n",
    "        inp, tar, _ = random.choice(train_dataset)\n",
    "        res = model.forward(inp)\n",
    "        if tar[list(res).index(max(res))] == 1:\n",
    "            guessed += 1\n",
    "    return guessed / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[(785, 65), (65, 10)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb3d018a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "EPOCH: 1\n",
      "@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 04:11:15,076\tWARNING worker.py:1398 -- WARNING: 48 PYTHON worker processes have been started on node: 5c46cbfedfe6d952f4786ccede9ea3259d6b0ea75446959eb9a6b0b9 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "2022-04-23 04:11:17,147\tWARNING worker.py:1398 -- WARNING: 61 PYTHON worker processes have been started on node: 5c46cbfedfe6d952f4786ccede9ea3259d6b0ea75446959eb9a6b0b9 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: accuracy=0.1484375\n",
      "Time since last testing (seconds) 20.91240096092224\n",
      "Estimated time per epoch:\n",
      "    seconds = 195.9491970038414\n",
      "    minutes = 3.265819950064023\n",
      "    hours   = 0.054430332501067054\n",
      "----------------------------------------\n",
      "Testing: accuracy=0.33984375\n",
      "Time since last testing (seconds) 13.093400239944458\n",
      "Estimated time per epoch:\n",
      "    seconds = 122.68516024827957\n",
      "    minutes = 2.0447526708046597\n",
      "    hours   = 0.03407921118007766\n",
      "----------------------------------------\n",
      "Testing: accuracy=0.509765625\n",
      "Time since last testing (seconds) 15.629865646362305\n",
      "Estimated time per epoch:\n",
      "    seconds = 146.4518411064148\n",
      "    minutes = 2.4408640184402466\n",
      "    hours   = 0.04068106697400411\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20140/3225737118.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0mlast_test_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgradient_calculator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m         \u001B[1;31m# print(list(map(lambda x: x.shape, grad)))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mrms_prop_optimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20140/3450939431.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[0midx\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m                 \u001B[0minp_ref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m                 \u001B[0mtar_ref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtar\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m\"init\"\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mis_client_mode_enabled_by_default\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 105\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    106\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\ray\\worker.py\u001B[0m in \u001B[0;36mput\u001B[1;34m(value, _owner)\u001B[0m\n\u001B[0;32m   1886\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mprofiling\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ray.put\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1887\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1888\u001B[1;33m             \u001B[0mobject_ref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mworker\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mput_object\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mowner_address\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserialize_owner_address\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1889\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mObjectStoreFullError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1890\u001B[0m             logger.info(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\ray\\worker.py\u001B[0m in \u001B[0;36mput_object\u001B[1;34m(self, value, object_ref, owner_address)\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;31m# reference counter.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m         return ray.ObjectRef(\n\u001B[1;32m--> 315\u001B[1;33m             self.core_worker.put_serialized_object_and_increment_local_ref(\n\u001B[0m\u001B[0;32m    316\u001B[0m                 \u001B[0mserialized_value\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject_ref\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mobject_ref\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mowner_address\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mowner_address\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m             ),\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "err = []\n",
    "guessed = 0\n",
    "\n",
    "testing_step = 100\n",
    "\n",
    "for epoch in range(50):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@@')\n",
    "    print(f'EPOCH: {epoch+1}')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@@')\n",
    "\n",
    "    last_test_time = time.time()\n",
    "    for i, batch in enumerate(batches):\n",
    "        grad = gradient_calculator.run(batch)\n",
    "        # print(list(map(lambda x: x.shape, grad)))\n",
    "        rms_prop_optimizer.step(grad)\n",
    "\n",
    "        if i % testing_step == testing_step - 1:\n",
    "            now = time.time()\n",
    "            elapsed = now - last_test_time\n",
    "            last_test_time = now\n",
    "            \n",
    "            time_per_epoch = elapsed * len(batches) / testing_step\n",
    "            \n",
    "            print(f'Testing: accuracy={test(model, train_dataset)}')\n",
    "            print(f'Time since last testing (seconds) {elapsed}')\n",
    "            print(f'Estimated time per epoch:')\n",
    "            print(f'    seconds = {time_per_epoch}')\n",
    "            print(f'    minutes = {time_per_epoch / 60}')\n",
    "            print(f'    hours   = {time_per_epoch / 60 / 60}')\n",
    "            print(f'----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cea3b857",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqUlEQVR4nGNgoAuQuLoTwWFCk+xQuItTY+m/9bhNff7NGqec9sfnOOXYr/4rxSnp9vevFjIfzbVrruHUWfBXG4WPotOT4Q1Ojfr/FqIKsCCxvf6/0mb5fgu7zkV/j37/9zEIl+Tfv//+flTD7iAGhml6DDwcWHUu/hHPEP5vJ1Y5hkU7GMSu/s3HLtn0uv/c/9vC2CXlnvz9+68QuxwDg0Hn5wbszhkkAACaRTisxTiG+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x13FB73ED0D0>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(train_dataset))\n",
    "inp, _, img = train_dataset[idx]\n",
    "\n",
    "res = model.forward(inp)\n",
    "pred = list(res).index(res.max())\n",
    "print(pred)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "45114acb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.38602826 -0.19510475 -0.19510475 -0.19510475\n",
      "  1.1795444   1.306827    1.803228   -0.09327888  1.688674    2.8214867\n",
      "  2.7196608   1.1922727  -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.04236595  0.03400347  0.77224106  1.5359352\n",
      "  1.7395868   2.7960303   2.7960303   2.7960303   2.7960303   2.7960303\n",
      "  2.4396398   1.7650434   2.7960303   2.6560197   2.0577927   0.39039403\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296  0.1994705\n",
      "  2.6051068   2.7960303   2.7960303   2.7960303   2.7960303   2.7960303\n",
      "  2.7960303   2.7960303   2.7960303   2.7705739   0.7595128   0.61950225\n",
      "  0.61950225  0.28856814  0.07218818 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.19510475  2.3632703   2.7960303\n",
      "  2.7960303   2.7960303   2.7960303   2.7960303   2.0959773   1.8923256\n",
      "  2.7196608   2.6432915  -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296  0.59404576  1.5613916   0.937708    2.7960303\n",
      "  2.7960303   2.185075   -0.2842024  -0.42421296  0.12310111  1.5359352\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.2460177  -0.41148472  1.5359352   2.7960303   0.7213281\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296  1.3450117   2.7960303   1.9941516  -0.3987565  -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.2842024\n",
      "  1.9941516   2.7960303   0.46676344 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296  0.02127524  2.6432915\n",
      "  2.4396398   1.6123046   0.95043623 -0.41148472 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296  0.60677403  2.6305633   2.7960303\n",
      "  2.7960303   1.0904468  -0.10600711 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296  0.14855757  1.9432386   2.7960303   2.7960303\n",
      "  1.4850222  -0.08055065 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.2205612   0.7595128   2.783302    2.7960303   1.9559668\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296  2.7451172   2.7960303   2.7451172   0.39039403 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296  0.1612858   1.2304575   1.905054    2.7960303\n",
      "  2.7960303   2.2105315  -0.3987565  -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296  0.07218818  1.4595658\n",
      "  2.4905527   2.7960303   2.7960303   2.7960303   2.7578456   1.8923256\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.11873534  1.0268056   2.3887267   2.7960303   2.7960303   2.7960303\n",
      "  2.7960303   2.1341622   0.5685893  -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.13146357  0.41585052  2.286901    2.7960303\n",
      "  2.7960303   2.7960303   2.7960303   2.0959773   0.60677403 -0.3987565\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.19510475  1.7523152\n",
      "  2.3632703   2.7960303   2.7960303   2.7960303   2.7960303   2.0577927\n",
      "  0.59404576 -0.30965886 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  0.2758399   1.7650434   2.452368    2.7960303   2.7960303   2.7960303\n",
      "  2.7960303   2.681476    1.2686423  -0.2842024  -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296  1.306827    2.7960303\n",
      "  2.7960303   2.7960303   2.2741728   1.2940987   1.2559141  -0.2205612\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      " -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec3c89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58918fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fbeee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "softmax_d(np.array(39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad243a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IND = random.randint(1, 10000)\n",
    "inp = train_dataset[IND][0]\n",
    "tar = train_dataset[IND][1]\n",
    "\n",
    "res = model.forward(inp)\n",
    "print(res)\n",
    "print(tar)\n",
    "print(sum(abs(res - tar)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}